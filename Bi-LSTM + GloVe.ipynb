{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536a2d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv(r'C:\\Users\\mtsil\\OneDrive\\Documents\\finalcorpus.csv', ';', encoding= 'unicode_escape') \n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06af8588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Bidirectional\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444da224",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1['text']\n",
    "y = df1['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249be135",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test , y_train, y_test = train_test_split(X, y , test_size = 0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9350d6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "oov_token = \"<OOV>\"\n",
    "max_length = 100\n",
    "padding_type = \"post\"\n",
    "trunction_type=\"post\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3e0199",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05b2aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5141fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ebe642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X_train_padded = pad_sequences(X_train_sequences,maxlen=max_length, padding=padding_type, \n",
    "                       truncating=trunction_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb827519",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6431238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_padded = pad_sequences(X_test_sequences,maxlen=max_length, \n",
    "                               padding=padding_type, truncating=trunction_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97e9d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f527ed24",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "f = open(r\"C:\\Users\\mtsil\\OneDrive\\Documents\\glove.twitter.27B.100d.txt\", encoding=\"utf8\")\n",
    "for line in f:\n",
    "         values = line.split()\n",
    "         word = values[0]\n",
    "         coefs = np.asarray(values[1:], dtype='float32')\n",
    "         embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0723190",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, max_length))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a1db28",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231479a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            max_length,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_length,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2f333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "model = Sequential()\n",
    "embedding_dim = 50\n",
    "input_length = 100\n",
    "model = Sequential([\n",
    "    embedding_layer,\n",
    "  Bidirectional(LSTM(embedding_dim, return_sequences=True)),\n",
    "    Dense(32,activation='relu'),\n",
    "    Dropout(0.1), # either add a dropout layer or a new Dense layer\n",
    "  Dense(1,activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915459ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_padded, y_train, epochs=10, shuffle = True, batch_size=64, validation_data=(X_test_padded, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0502c6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test_padded, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70aadc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191948f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca15d686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "history.history\n",
    "\n",
    "history_df = pd.DataFrame(list(zip(history.history['loss'],history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy'])),\n",
    "                          columns=['loss','accuracy','val_loss','val_accurary'])\n",
    "history_df['epoch']=list(range(1,len(history_df['loss'])+1,1))\n",
    "history_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
